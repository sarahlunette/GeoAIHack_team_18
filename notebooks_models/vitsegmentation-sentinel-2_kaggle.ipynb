{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91683,"databundleVersionId":11007828,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport shutil\nimport os\nimport re\n\ndef generate_label_mapping(root_dir, other_dir, input_subdir, output_csv):\n    \"\"\"\n    Generate a CSV mapping input chips to corresponding segmentation maps.\ns2_train/s2_train//chips/chip_20170701_S2A_MSIL2A_T42RWQ_20170526T054641_2_20.tif'\n    Args:\n        root_dir (str or Path): Root directory containing the subdirectories for chips and segmentation maps.\n        input_subdir (str): Subdirectory path for chips within the root directory.\n        output_csv (str or Path): Output path for the generated CSV file.\n    \"\"\"\n    root_dir = Path(root_dir)\n    chips_orig = os.listdir(root_dir / input_subdir / \"chips\")\n\n    chips = [chip.replace(\"chip\", f\"{input_subdir}/chips/chip\") for chip in chips_orig]\n    seg_maps = [chip.replace(\"chip\", f\"{input_subdir}/seg_maps/seg_map\") for chip in chips_orig]\n\n    df = pd.DataFrame({\"Input\": chips, \"Label\": seg_maps})\n    df.to_csv(other_dir + '/' + output_csv, index=False)\n    \n    print(f\"Number of rows is: {df.shape[0]}\")\n    print(f\"CSV generated and saved to: {root_dir / output_csv}\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:33:01.029870Z","iopub.execute_input":"2025-02-12T17:33:01.030194Z","iopub.status.idle":"2025-02-12T17:33:01.409999Z","shell.execute_reply.started":"2025-02-12T17:33:01.030145Z","shell.execute_reply":"2025-02-12T17:33:01.409037Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"generate_label_mapping('/kaggle/input/geo-ai-hack/', '/kaggle/working/',\"s2_train/s2_train\", \"s2_train_ds.csv\")\ngenerate_label_mapping('/kaggle/input/geo-ai-hack/', '/kaggle/working/', \"s2_test/s2_test\", \"s2_test_ds.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:33:01.410921Z","iopub.execute_input":"2025-02-12T17:33:01.411357Z","iopub.status.idle":"2025-02-12T17:33:01.754536Z","shell.execute_reply.started":"2025-02-12T17:33:01.411332Z","shell.execute_reply":"2025-02-12T17:33:01.753680Z"}},"outputs":[{"name":"stdout","text":"Number of rows is: 11764\nCSV generated and saved to: /kaggle/input/geo-ai-hack/s2_train_ds.csv\nNumber of rows is: 3937\nCSV generated and saved to: /kaggle/input/geo-ai-hack/s2_test_ds.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install rasterio\nimport os\nimport torch\nimport numpy as np\nimport rasterio\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom transformers import ViTModel, ViTConfig\nimport torch.optim as optim\nimport torch.nn as nn\nimport pandas as pd\nfrom tqdm import tqdm\n\n# Custom Dataset Class with 3 Time-Step Stacking\nclass CustomSegmentationDataset(Dataset):\n    def __init__(self, image_paths, mask_paths=None, transform=None, is_test=False):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths if not is_test else None\n        self.transform = transform\n        self.is_test = is_test\n        self.samples = []\n        \n        # ğŸ”¥ Ne garder que les x premiers Ã©chantillons\n        self.samples = self.samples[:10]  # For debugging purposes\n\n        if not is_test:\n            for i in range(len(image_paths) - 2):  # Ensure 3 consecutive images exist\n                if os.path.exists(image_paths[i]) and os.path.exists(image_paths[i+1]) and os.path.exists(image_paths[i+2]) and os.path.exists(mask_paths[i]):\n                    self.samples.append((image_paths[i], image_paths[i+1], image_paths[i+2], mask_paths[i]))\n                else:\n                    print(f\"Missing files for index {i}: {[image_paths[i], image_paths[i+1], image_paths[i+2], mask_paths[i]]}\")\n        else:\n            for i in range(len(image_paths) - 2):\n                if os.path.exists(image_paths[i]) and os.path.exists(image_paths[i+1]) and os.path.exists(image_paths[i+2]):\n                    self.samples.append((image_paths[i], image_paths[i+1], image_paths[i+2], None))\n                else:\n                    print(f\"Missing files for index {i}: {[image_paths[i], image_paths[i+1], image_paths[i+2]]}\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img1_path, img2_path, img3_path, mask_path = self.samples[idx]\n        preprocessing = Preprocessing()\n        img1 = preprocessing.preprocess_image(img1_path)\n        img2 = preprocessing.preprocess_image(img2_path)\n        img3 = preprocessing.preprocess_image(img3_path)\n        \n        # Stack images as additional channels (8*3 = 24 channels total)\n        image = np.concatenate([img1, img2, img3], axis=-1)\n        image = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32)\n\n        if self.is_test:\n            return image, {\"image_id\": torch.tensor([idx])}\n        else:\n            mask = plt.imread(mask_path)\n            if mask.ndim == 3:\n                mask = mask[..., 0]\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n\n# Preprocessing Class for 8-Channel Images\nimport cv2  # OpenCV for resizing\n\nclass Preprocessing:\n    def preprocess_image(self, image_path):\n        with rasterio.open(image_path) as src:\n            bands = [src.read(i) for i in range(1, 7)]\n        \n        ndvi = self.compute_ndvi(bands[2], bands[3])\n        evi = self.compute_evi(bands[3], bands[2], bands[0])\n        ndwi = self.compute_ndwi(bands[1], bands[3])\n        nbr = self.compute_nbr(bands[3], bands[5])\n        normalized_bands = [self.normalize_band(band) for band in bands]\n        image = np.stack(normalized_bands + [ndvi, evi, ndwi, nbr], axis=-1)  # Shape: (H, W, 8)\n\n        # ğŸ”¥ Resize to 256x256\n        image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_NEAREST)\n        \n        return image\n\n    def normalize_band(self, band):\n        min_val, max_val = np.min(band), np.max(band)\n        return (band - min_val) / (max_val - min_val + 1e-6)\n\n    def compute_ndvi(self, red, nir):\n        return (nir - red) / (nir + red + 1e-6)\n\n    def compute_evi(self, nir, red, blue, g=2.5, c1=6, c2=7.5, l=1, epsilon=1e-6):\n        denominator = nir + c1 * red - c2 * blue + l\n        denominator = np.where(denominator == 0, epsilon, denominator)  # Avoid zero division\n        return np.clip(g * (nir - red) / denominator, 0, 1)\n        \n # TODO: add ndwi and change for 10 bands       \n    def compute_ndwi(self, green, nir, epsilon=1e-6):\n        denominator = green + nir\n        denominator = np.where(denominator == 0, epsilon, denominator)  # Avoid zero division\n        return (green - nir) / denominator\n    \n    def compute_nbr(self, nir, swir2, epsilon=1e-6):\n        denominator = nir + swir2\n        denominator = np.where(denominator == 0, epsilon, denominator)  # Avoid zero division\n        return (nir - swir2) / denominator\n\n\n# Vision Transformer for Segmentation (Updated for 30 channels) # 24\nimport torch.nn.functional as F\n\nclass ViTSegmentationModel(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ViTSegmentationModel, self).__init__()\n\n        # ViT configuration with 30 channels # 24\n        config = ViTConfig(\n            image_size=256,        \n            patch_size=16,         \n            num_channels=30,      # 24 \n            hidden_size=384,       \n            num_attention_heads=6, \n            num_hidden_layers=12,  \n            intermediate_size=768, \n            num_classes=num_classes\n        )\n\n        self.vit = ViTModel(config)\n\n        # Segmentation decoder head\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(384, 128, kernel_size=2, stride=2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, num_classes, kernel_size=2, stride=2)\n        )\n\n        # Final upsampling layer to match 256Ã—256\n        self.upsample = nn.Upsample(size=(256, 256), mode='bilinear', align_corners=False)\n\n    def forward(self, x):\n        batch_size = x.shape[0]\n        features = self.vit(x).last_hidden_state  # (batch_size, 257, hidden_size)\n\n        # Remove CLS token\n        features = features[:, 1:, :]  # Shape: (batch_size, 256, hidden_size)\n\n        # Reshape for decoder\n        spatial_size = int(features.shape[1] ** 0.5)  # Should be 16\n        features = features.permute(0, 2, 1).reshape(batch_size, 384, spatial_size, spatial_size)  # (batch, 384, 16, 16)\n\n        output = self.decoder(features)  # (batch, num_classes, 64, 64)\n\n        # Upsample to 256Ã—256\n        output = self.upsample(output)  # (batch, num_classes, 256, 256)\n\n        return output\n\n# Update the input image size and patch size based on your dataset dimensions\n\n# Training Setup\ntrain_csv = pd.read_csv(\"/kaggle/working/s2_train_ds.csv\")\ntest_csv = pd.read_csv(\"/kaggle/working/s2_test_ds.csv\")\ntrain_image_paths = train_csv[\"Input\"].tolist()\ntrain_mask_paths = train_csv[\"Label\"].tolist()\ntest_image_paths = test_csv[\"Input\"].tolist()\n\n%cd /kaggle/input/geo-ai-hack\n\ntrain_dataset = CustomSegmentationDataset(image_paths=train_image_paths, mask_paths=train_mask_paths)\ntest_dataset = CustomSegmentationDataset(image_paths=test_image_paths, is_test=True)\ntrain_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n\n# Model Training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ViTSegmentationModel().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(10):\n    model.train()\n    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n    for images, masks in pbar:\n        images, masks = images.to(device), masks.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, masks)\n        loss.backward()\n        optimizer.step()\n        pbar.set_postfix({\"Loss\": loss.item()})\n    print(f\"Epoch {epoch+1} complete\")\n\n# Save Model\ntorch.save(model.state_dict(), \"vit_segmentation.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:33:01.755429Z","iopub.execute_input":"2025-02-12T17:33:01.755654Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.3.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.12.14)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\nDownloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.3\n/kaggle/input/geo-ai-hack\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}