{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91683,"databundleVersionId":11007828,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport shutil\nimport os\nimport re\n\ndef generate_label_mapping(root_dir, other_dir, input_subdir, output_csv):\n    \"\"\"\n    Generate a CSV mapping input chips to corresponding segmentation maps.\n\n    Args:\n        root_dir (str or Path): Root directory containing the subdirectories for chips and segmentation maps.\n        input_subdir (str): Subdirectory path for chips within the root directory.\n        output_csv (str or Path): Output path for the generated CSV file.\n    \"\"\"\n    root_dir = Path(root_dir)\n    chips_orig = os.listdir(root_dir / input_subdir / \"chips\")\n\n    chips = [chip.replace(\"chip\", f\"{input_subdir}/chips/chip\") for chip in chips_orig]\n    seg_maps = [chip.replace(\"chip\", f\"{input_subdir}/seg_maps/seg_map\") for chip in chips_orig]\n\n    df = pd.DataFrame({\"Input\": chips, \"Label\": seg_maps})\n    df.to_csv(other_dir + '/' + output_csv, index=False)\n    \n    print(f\"Number of rows is: {df.shape[0]}\")\n    print(f\"CSV generated and saved to: {root_dir / output_csv}\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T14:08:53.962169Z","iopub.execute_input":"2025-02-05T14:08:53.962531Z","iopub.status.idle":"2025-02-05T14:08:54.687578Z","shell.execute_reply.started":"2025-02-05T14:08:53.962490Z","shell.execute_reply":"2025-02-05T14:08:54.686437Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"generate_label_mapping('/kaggle/input/geo-ai-hack/', '/kaggle/working/',\"s2_train/s2_train/\", \"s2_train_ds.csv\")\ngenerate_label_mapping('/kaggle/input/geo-ai-hack/', '/kaggle/working/', \"s2_test/s2_test/\", \"s2_test_ds.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T14:08:54.688748Z","iopub.execute_input":"2025-02-05T14:08:54.689277Z","iopub.status.idle":"2025-02-05T14:08:55.743988Z","shell.execute_reply.started":"2025-02-05T14:08:54.689246Z","shell.execute_reply":"2025-02-05T14:08:55.742566Z"}},"outputs":[{"name":"stdout","text":"Number of rows is: 11764\nCSV generated and saved to: /kaggle/input/geo-ai-hack/s2_train_ds.csv\nNumber of rows is: 3937\nCSV generated and saved to: /kaggle/input/geo-ai-hack/s2_test_ds.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport rasterio\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom transformers import ViTModel\nimport torch.optim as optim\nimport torch.nn as nn\nimport pandas as pd\nfrom tqdm import tqdm\n\n# Custom Dataset Class with 3 Time-Step Stacking\nclass CustomSegmentationDataset(Dataset):\n    def __init__(self, image_paths, mask_paths=None, transform=None, is_test=False):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths if not is_test else None\n        self.transform = transform\n        self.is_test = is_test\n        self.samples = []\n\n        if not is_test:\n            for i in range(len(image_paths) - 2):  # Ensure 3 consecutive images exist\n                if os.path.exists(image_paths[i]) and os.path.exists(image_paths[i+1]) and os.path.exists(image_paths[i+2]) and os.path.exists(mask_paths[i]):\n                    self.samples.append((image_paths[i], image_paths[i+1], image_paths[i+2], mask_paths[i]))\n        else:\n            for i in range(len(image_paths) - 2):\n                if os.path.exists(image_paths[i]) and os.path.exists(image_paths[i+1]) and os.path.exists(image_paths[i+2]):\n                    self.samples.append((image_paths[i], image_paths[i+1], image_paths[i+2], None))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img1_path, img2_path, img3_path, mask_path = self.samples[idx]\n        preprocessing = Preprocessing()\n        img1 = preprocessing.preprocess_image(img1_path)\n        img2 = preprocessing.preprocess_image(img2_path)\n        img3 = preprocessing.preprocess_image(img3_path)\n        \n        # Stack images as additional channels (8*3 = 24 channels total)\n        image = np.concatenate([img1, img2, img3], axis=-1)\n        image = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32)\n\n        if self.is_test:\n            return image, {\"image_id\": torch.tensor([idx])}\n        else:\n            mask = plt.imread(mask_path)\n            if mask.ndim == 3:\n                mask = mask[..., 0]\n            mask = torch.tensor(mask, dtype=torch.long)\n            return image, mask\n\n# Preprocessing Class for 8-Channel Images\nclass Preprocessing:\n    def preprocess_image(self, image_path):\n        with rasterio.open(image_path) as src:\n            bands = [src.read(i) for i in range(1, 7)]\n        \n        ndvi = self.compute_ndvi(bands[2], bands[3])\n        evi = self.compute_evi(bands[3], bands[2], bands[0])\n        normalized_bands = [self.normalize_band(band) for band in bands]\n        image = np.stack(normalized_bands + [ndvi, evi], axis=-1)\n        return image\n\n    def normalize_band(self, band):\n        return (band - np.min(band)) / (np.max(band) - np.min(band))\n\n    def compute_ndvi(self, red, nir):\n        return (nir - red) / (nir + red + 1e-6)\n\n    def compute_evi(self, nir, red, blue, g=2.5, c1=6, c2=7.5, l=1):\n        return np.clip(g * (nir - red) / (nir + c1 * red - c2 * blue + l), 0, 1)\n\n# Vision Transformer for Segmentation\nclass ViTSegmentationModel(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ViTSegmentationModel, self).__init__()\n        self.vit = ViTModel.from_pretrained(\"facebook/dino-vits16\")\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(384, 128, kernel_size=2, stride=2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, num_classes, kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        features = self.vit(x).last_hidden_state\n        features = features.permute(0, 2, 1).reshape(-1, 384, 24, 24)\n        return self.decoder(features)\n\n# Training Setup\ntrain_csv = pd.read_csv(\"/kaggle/working/s2_train_ds.csv\")\ntest_csv = pd.read_csv(\"/kaggle/working/s2_test_ds.csv\")\ntrain_image_paths = train_csv[\"Input\"].tolist()\ntrain_mask_paths = train_csv[\"Label\"].tolist()\ntest_image_paths = test_csv[\"Input\"].tolist()\n\ntrain_dataset = CustomSegmentationDataset(image_paths=train_image_paths, mask_paths=train_mask_paths)\ntest_dataset = CustomSegmentationDataset(image_paths=test_image_paths, is_test=True)\ntrain_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n\n# Model Training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ViTSegmentationModel().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(10):\n    model.train()\n    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n    for images, masks in pbar:\n        images, masks = images.to(device), masks.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, masks)\n        loss.backward()\n        optimizer.step()\n        pbar.set_postfix({\"Loss\": loss.item()})\n    print(f\"Epoch {epoch+1} complete\")\n\n# Save Model\ntorch.save(model.state_dict(), \"vit_segmentation.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T14:09:12.257752Z","iopub.execute_input":"2025-02-05T14:09:12.258137Z","iopub.status.idle":"2025-02-05T14:09:15.546239Z","shell.execute_reply.started":"2025-02-05T14:09:12.258104Z","shell.execute_reply":"2025-02-05T14:09:15.544537Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-27175b8f550e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rasterio'"],"ename":"ModuleNotFoundError","evalue":"No module named 'rasterio'","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}